{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing the MNIST example, but using Tensor Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 9s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f1c51631748>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD8CAYAAAAfZJO2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFZ9JREFUeJzt3W2MlOW9x/HvH9TaIi2QXe2K4HoobUptBLMVE04stqnapi3ywgbTIBrL8gJKTSAt4gt5URNifThajD2LECDxoUThiA2pRSPhkKYU1hIEkSO1K+5hu8ChVVqTWvB/Xsy95ww7M9fMztwzc1+7v08y2Zn7fz9cO8pvr/u6n8zdERGJ1ahmN0BEpBYKMRGJmkJMRKKmEBORqCnERCRqCjERiZpCTESiphATkagpxEQkahc0cmMtLS3e3t7eyE2KjCg9PT2cOnXKalmHmQ3lMp6X3f2WWrZXq5pCzMxuAR4DRgNPufvq0Pzt7e3s27evlk2KSEBHR0ejN9kSKprZJGAT8FngY6DL3R8zs1XAQuBkMutKd9+eLHMvcDdwDljq7i+HtlF1iJnZaOAJ4BtAL7DXzLa5+5vVrlNEssGsss5cBddenwWWufvrZjYW6DazHUntUXd/aNB2pwHzgC8BlwOvmNnn3f1cqQ3UMiZ2HXDU3d9x94+A54A5NaxPRDJi1KhRFb3Kcfc+d389eX8GOAxMDCwyB3jO3f/h7n8CjpLLmtJtrfi3KjQReC/vc2+xxplZp5ntM7N9J0+eHFwWkQwys4peQ1xnOzAD2JNMWmJmB8xsvZmNT6ZVlCv5agmxYr9BQd/S3bvcvcPdO1pbW2vYnIg0QqUBloRYy0AnJXl1lljnJcALwD3u/gHwJDAFmA70AQ8PzFpk8eA+ay0D+73ApLzPVwDHa1ifiGTEEHpZp9w9eDTBzC4kF2BPu/sWAHfvz6uvBX6VfBxyrtTSE9sLTDWzq8zsInKDcdtqWJ+IZERau5OWm2kdcNjdH8mb3pY321zgYPJ+GzDPzD5hZlcBU4Hfh7ZRdU/M3c+a2RLgZXKnWKx390PVrk9EsmOo410Bs4D5wBtmtj+ZthK43cymk9tV7AEWAbj7ITPbDLxJ7sjm4tCRSajxPLHkvI7ttaxDRLLFzCo68lgJd99N8XGukrnh7g8AD1S6jYaesS8icUixJ1Z3CjERKaAQE5GoKcREJGoKMRGJVpoD+42gEBORAuqJiUjUFGIiEjWFmIhEq5o7VDSTQkxECijERCRqOjopIlFTT0xEoqUxMRGJnkJMRKKmEBORqGlgX0SipTExEYmeQkxEoqYQE5GoKcREJGoKMRGJlm6KKCLRU09MRKKmEBORqCnERCRaOtlVRKKnEBORqOnopIhEbcT0xMysBzgDnAPOuntHGo2S9Jw7dy5Yf//99+u6/TVr1pSsffjhh8Fljxw5Eqw/8cQTwfry5ctL1p599tngshdffHGwvmLFimD9/vvvD9azbCSOid3o7qdSWI+IZMRICzERGWZGUog58Bszc+Df3b0rhTaJSJONpIH9We5+3MwuBXaY2Vvuvit/BjPrBDoBJk+eXOPmRKTeYhsTqylu3f148vMEsBW4rsg8Xe7e4e4dra2ttWxORBpkIMjKvSpYzyQze83MDpvZITP7UTJ9gpntMLO3k5/jk+lmZo+b2VEzO2Bm15bbRtUhZmZjzGzswHvgJuBgtesTkexIK8SAs8Ayd/8icD2w2MymASuAV919KvBq8hngm8DU5NUJPFluA7XsTl4GbE1+kQuAZ9z91zWsT0QyIq3dSXfvA/qS92fM7DAwEZgDzE5m2wjsBH6STN/k7g78zszGmVlbsp6iqg4xd38HuKba5UeSY8eOBesfffRRsP7b3/42WN+9e3fJ2l//+tfgss8//3yw3kyTJk0K1n/4wx8G61u3bi1ZGzt2bHDZa64J/6/91a9+NViP3RBCrMXM9uV97ip1gM/M2oEZwB7gsoFgcve+ZFwdcgH3Xt5ivcm09ENMRIanId4U8VQlJ7mb2SXAC8A97v5BICSLFTy07niOo4pIw6Q4JoaZXUguwJ529y3J5H4za0vqbcCJZHovkN8FvwI4Hlq/QkxECqR4dNKAdcBhd38kr7QNWJC8XwC8mDf9juQo5fXA+6HxMNDupIgUkeJ5YrOA+cAbZrY/mbYSWA1sNrO7gWPAbUltO/At4CjwIXBXuQ0oxETkPGme7Oruuyk+zgXw9SLzO7B4KNtQiIlIgZjO2FeIpeAPf/hDsP61r30tWK/37XCyavTo0cH6T3/602B9zJgxwfr3v//9krXLL788uOz48eOD9S984QvBeuxG0rWTIjIMqScmItGK7QJwhZiIFFCIiUjUFGIiEjUN7ItItDQmJiLRU4iNMFdeeWWw3tLSEqxn+TyxmTNnBuvlzqd67bXXStYuuuii4LLz588P1qV+FGIiEjWFmIhETSEmItEa4k0Rm04hJiIF1BMTkagpxEQkagoxEYmWTnYdgSZMmBCs/+xnPwvWX3rppWB9xowZwfrSpUuD9ZDp06cH66+88kqwXu6eXgcPln6e8uOPPx5cVppHISYiUdPRSRGJlnYnRSR6CjERiZpCTESiphATkWjpsiMRid6w6omZ2Xrg28AJd786mTYB+CXQDvQA33P3v9SvmXG79dZbg/Vyz6UcO3ZssH7gwIGStaeeeiq47PLly4P1cueBlXP11VeXrHV1ddW0bqmfmEKskj7jBuCWQdNWAK+6+1Tg1eSziAwTA6dZlHtlQdkQc/ddwOlBk+cAG5P3G4FwV0NEohJTiFU7JnaZu/cBuHufmV2aYptEpImyFFCVqPvAvpl1Ap0AkydPrvfmRCQFMR2drLal/WbWBpD8PFFqRnfvcvcOd+9obW2tcnMi0kgx7U5WG2LbgAXJ+wXAi+k0R0SyIKYQq+QUi2eB2UCLmfUC9wOrgc1mdjdwDLitno0UkcbJUkBVomyIufvtJUpfT7ktI9anP/3pmpb/zGc+U/Wy5c4jmzdvXrAe09iJVC6tECtxnukqYCFwMpltpbtvT2r3AncD54Cl7v5yuW3ojH0RKZDiH6cNwBpg06Dpj7r7Q/kTzGwaMA/4EnA58IqZfd7dzwXbmlZLRWT4SGtMrMR5pqXMAZ5z93+4+5+Ao8B15RZSiInIeSoNsBp3OZeY2QEzW29m45NpE4H38ubpTaYFKcREpMAQQqzFzPblvTorWP2TwBRgOtAHPDyw2SLzermVaUxMRAoMoZd1yt07hrJud+/P285a4FfJx15gUt6sVwDHy61PPTERKVDP3cmBE+UTc4GBR2JtA+aZ2SfM7CpgKvD7cutTT2wYWLVqVclad3d3cNmdO3cG6+Ue2XbTTTcF6xKfNG+KWOI809lmNp3crmIPsAjA3Q+Z2WbgTeAssLjckUlQiIlIEWmdJ1biPNN1gfkfAB4YyjYUYiJSYFidsS8iI49CTESiphATkWgNuwvARWTkienCfoWYiBRQT0waKvRYtbVr1waXvfbaa4P1hQsXBus33nhjsN7RUfpk7sWLFweXjekf0nAT03evEBOR82hMTESipxATkahpYF9EoqaemIhES2NiIhI9hZiIRE0hJpkxZcqUYH3Dhg3B+l133RWsb9o0+CE2ldf//ve/B5e94447gvW2trZgXaqnEBORaKV5U8RGUIiJSAH1xEQkagoxEYmaQkxEoqYQE5Fo6WRXEYnesDo6aWbrgW8DJ9z96mTaKmAhcDKZbaW7b69XI6V+5s6dG6x/7nOfC9aXLVsWrIeeW3nvvfcGl3333XeD9fvuuy9YnzhxYrAupcXUE6skbjcAtxSZ/qi7T09eCjCRYaSeTwBPW9memLvvMrP2+jdFRLIgSwFViVp2fJeY2QEzW29m41NrkYg0XUw9sWpD7ElgCjAd6AMeLjWjmXWa2T4z23fy5MlSs4lIhowaNaqiVxZU1Qp373f3c+7+MbAWuC4wb5e7d7h7R2tra7XtFJEGGvY9MTPLv33AXOBgOs0RkWarNMCyEmKVnGLxLDAbaDGzXuB+YLaZTQcc6AEW1bGNItJgWQmoSlRydPL2IpPX1aEtkkFf/vKXg/XNmzcH6y+99FLJ2p133hlc9he/+EWw/vbbbwfrO3bsCNaltGEVYiIy8ijERCRauimiiEQvpp5YPHErIg2T1tHJ5GT4E2Z2MG/aBDPbYWZvJz/HJ9PNzB43s6PJifTXVtJWhZiIFEjxFIsNFF57vQJ41d2nAq8mnwG+CUxNXp3kTqovSyEmIgXSCjF33wWcHjR5DrAxeb8RuDVv+ibP+R0wbtA5qUVpTExqMm7cuGB9/vz5JWs/+MEPgsv+85//DNZ37doVrO/cubNkbfbs2cFlR7IGnMh6mbv3Abh7n5ldmkyfCLyXN19vMq0vtDKFmIgUGMLRyRYz25f3ucvdu6rcbLHk9HILKcREpMAQemKn3L1jiKvvN7O2pBfWBpxIpvcCk/LmuwI4Xm5lGhMTkQJ1vnZyG7Ageb8AeDFv+h3JUcrrgfcHdjtD1BMTkfOkOSZW4trr1cBmM7sbOAbclsy+HfgWcBT4ELirkm0oxESkQFohVuLaa4CvF5nXgcVD3YZCTEQK6LIjEYlWlu4VVgmFmAQdOHAgWH/++eeD9b1795aslTsPrJxp06YF6zfccENN6x/JFGIiEjWFmIhETSEmIlFTiIlItHRTRBGJnnpiIhI1hZiIRE0hJplx5MiRYP3nP/95sL5ly5Zg/c9//vOQ21SpCy4I/+/Z1ha+X15M4zpZopNdRSR6Mf0BUIiJSAH1xEQkagoxEYmWxsREJHoKMRGJmkJMRKI2rI5OmtkkYBPwWeBjco9keszMJgC/BNqBHuB77v6X+jV15Cp3LtYzzzxTsrZmzZrgsj09PdU0KRVf+cpXgvX77rsvWP/ud7+bZnMkEduYWCVxexZY5u5fBK4HFpvZNEo/ilxEIlfnpx2lqmyIuXufu7+evD8DHCb3VN5SjyIXkcjFFGJDGhMzs3ZgBrCH0o8iF5HIZSWgKlFxiJnZJcALwD3u/kGlv6SZdQKdAJMnT66mjSLSYDGFWEWHIMzsQnIB9rS7D1wR3J88gpxBjyI/j7t3uXuHu3e0tram0WYRqaOBmyJW8sqCsq2wXCSvAw67+yN5pVKPIheRyA23MbFZwHzgDTPbn0xbSelHkcsg/f39wfqhQ4eC9SVLlgTrb7311pDblJaZM2cG6z/+8Y9L1ubMmRNcNit/6UeirARUJcqGmLvvBkr9RgWPIheR+A2rEBORkSVLu4qVUIiJSIGYduUVYiJSQD0xEYmaQkxEoqUxMRGJnkJsGDp9+nTJ2qJFi4LL7t+/P1j/4x//WFWb0jBr1qxgfdmyZcH6zTffHKx/8pOfHHKbpPkUYiIStTSPTppZD3AGOAecdfeONO9HGM9xVBFpiEovORpib+1Gd5/u7h3J59TuR6gQE5ECDbh2MrX7ESrERKTAEEKsxcz25b06i6zOgd+YWXde/bz7EQJV349QY2IiUmAIvaxTebuIpcxy9+PJjVN3mFmqdyxQT0xECqS5O+nux5OfJ4CtwHVUeD/CSijEROQ8ad4U0czGmNnYgffATcBBUrwf4YjZndyzZ0+w/uCDDwbre/fuLVnr7e2tqk1p+dSnPlWytnTp0uCy5R6LNmbMmKraJHFL8Tyxy4CtyfouAJ5x91+b2V5Suh/hiAkxEalcWiHm7u8A1xSZ/j+kdD9ChZiIFNAZ+yISLV0ALiLR000RRSRq6omJSNQUYiISLY2JZdTWrVtrqtdi2rRpwfp3vvOdYH306NHB+vLly0vWxo0bF1xWpBiFmIhETSEmIlHT0UkRiZbGxEQkegoxEYmaQkxEoqYQE5GoDasQM7NJwCbgs8DHQJe7P2Zmq4CFwMlk1pXuvr1eDa3V6tWra6qLjBQDN0WMRSU9sbPAMnd/PblDY7eZ7Uhqj7r7Q/Vrnog0w7DqiSVPIhl4KskZMzsMTKx3w0SkeWIKsSH1Gc2sHZgBDNzreYmZHTCz9WY2vsQynQOPczp58mSxWUQkYxrw3MnUVBxiZnYJ8AJwj7t/ADwJTAGmk+upPVxsOXfvcvcOd+9obW1NockiUk91egJ43VR0dNLMLiQXYE+7+xYAd+/Pq68FflWXFopIw8U0sF+2pZaL23XAYXd/JG96W95sc8k9hklEhoHh1hObBcwH3jCz/cm0lcDtZjad3CPKe4BFdWmhiDRcVgKqEpUcndwNFPuNMntOmIhUL0u9rErojH0RKaAQE5GoKcREJFrD8bIjERlh1BMTkagpxEQkagoxEYmaQkxEoqXzxEQkejo6KSJRi6knFk/cikjDpHkBuJndYmZHzOyoma1Iu60KMRE5T5r3EzOz0cATwDeBaeRuHDEtzfYqxESkQIo9seuAo+7+jrt/BDwHzEmzrRoTE5ECKQ7sTwTey/vcC8xMa+XQ4BDr7u4+ZWbv5k1qAU41sg1DkNW2ZbVdoLZVK822XVnrCrq7u182s5YKZ7/YzPblfe5y9668z8W6a1596wo1NMTc/byb7JvZPnfvaGQbKpXVtmW1XaC2VStrbXP3W1JcXS8wKe/zFcDxFNevMTERqau9wFQzu8rMLgLmAdvS3IDGxESkbtz9rJktAV4GRgPr3f1Qmttodoh1lZ+labLatqy2C9S2amW5bTVz9+3U8Xb25p7qGJuISENpTExEotaUEKv3ZQi1MLMeM3vDzPYPOnTcjLasN7MTZnYwb9oEM9thZm8nP8dnqG2rzOy/k+9uv5l9q0ltm2Rmr5nZYTM7ZGY/SqY39bsLtCsT31usGr47mVyG8F/AN8gdft0L3O7ubza0ISWYWQ/Q4e5NP6fIzG4A/gZscverk2kPAqfdfXXyB2C8u/8kI21bBfzN3R9qdHsGta0NaHP3181sLNAN3ArcSRO/u0C7vkcGvrdYNaMnVvfLEIYLd98FnB40eQ6wMXm/kdw/goYr0bZMcPc+d389eX8GOEzuzPGmfneBdkkNmhFixS5DyNJ/SAd+Y2bdZtbZ7MYUcZm790HuHwVwaZPbM9gSMzuQ7G42ZVc3n5m1AzOAPWTouxvULsjY9xaTZoRY3S9DqNEsd7+W3FX3i5PdJqnMk8AUYDrQBzzczMaY2SXAC8A97v5BM9uSr0i7MvW9xaYZIVb3yxBq4e7Hk58ngK3kdn+zpD8ZWxkYYznR5Pb8H3fvd/dz7v4xsJYmfndmdiG5oHja3bckk5v+3RVrV5a+txg1I8TqfhlCtcxsTDLgipmNAW4CDoaXarhtwILk/QLgxSa25TwDAZGYS5O+O8vdI2YdcNjdH8krNfW7K9WurHxvsWrKya7JIeR/4/8vQ3ig4Y0owsz+hVzvC3JXMzzTzLaZ2bPAbHJ3OegH7gf+A9gMTAaOAbe5e8MH2Eu0bTa5XSIHeoBFA2NQDW7bvwL/CbwBfJxMXklu/Klp312gXbeTge8tVjpjX0SipjP2RSRqCjERiZpCTESiphATkagpxEQkagoxEYmaQkxEoqYQE5Go/S8TQhnt4bCmvAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(train_images[0], cmap = 'binary')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "test_images = test_images/255.0\n",
    "train_images = train_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/karthik/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28, 28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 7s 109us/sample - loss: 0.2538 - acc: 0.9276\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 6s 97us/sample - loss: 0.1141 - acc: 0.9658\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0783 - acc: 0.9757\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 6s 98us/sample - loss: 0.0587 - acc: 0.9821\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0453 - acc: 0.9863\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0367 - acc: 0.9885\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0278 - acc: 0.9915\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0231 - acc: 0.9929\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 6s 100us/sample - loss: 0.0194 - acc: 0.9938\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0164 - acc: 0.9950\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0141 - acc: 0.9958\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0113 - acc: 0.9963\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0084 - acc: 0.9974\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0084 - acc: 0.9974\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0079 - acc: 0.9977\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 6s 101us/sample - loss: 0.0074 - acc: 0.9980\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0063 - acc: 0.9983\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0057 - acc: 0.9983\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0064 - acc: 0.9977\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0058 - acc: 0.9983\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0045 - acc: 0.9987\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 6s 105us/sample - loss: 0.0061 - acc: 0.9980\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 6s 103us/sample - loss: 0.0044 - acc: 0.9987\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 6s 102us/sample - loss: 0.0055 - acc: 0.9980\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0042 - acc: 0.9987\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 6s 107us/sample - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 6s 106us/sample - loss: 0.0042 - acc: 0.9988\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 6s 104us/sample - loss: 0.0055 - acc: 0.9983\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 6s 108us/sample - loss: 0.0035 - acc: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1c61221860>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.1469 - acc: 0.9733\n"
     ]
    }
   ],
   "source": [
    "# Evaluate network performance on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-83fcd28124ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#predicted_labels += str(model.predict(img)) + \" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   4526\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4527\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4528\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEIAAAA/CAYAAABU6B73AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAAf5JREFUeJztmTG2qjAQhod3XhF3QGl2YWtlS0lpmdJSK0vcQex0F7gkdzB0cwtHL3B5iPchBv2/c1J4kuMk35mECUQiQoDoz6snEAoQoUCEAhEKRCgQoUCEAhEKRCh/B473ijI26jIIGaFAhBKsiNPpRNZaiqKIrLVkraXNZkPz+ZyOx2P/AUVkyHaXw+Eg0+lU6HKeNDZjTJe/utJpbsGIyPP8roBye1sRcRw3Lng2m32WiPIi0zQVZm4d07eIoeuITiwWCzLG3H7v9/vnBw0lI4wxlcPQe3/ri+O4snXSNO09I4IRkWVZ41nQdIA2bZu3EdEmo94eZHwiRESYWZbLJUSUaRLyYDHVWUSwJTbRpcyuUxQF7Xa73mMFLWJQQt0a3vvPvGvUKdcNSZJIkiSVWiPLsvcXUc8GZhZmltVq9ZusGK+If1WRzPybx+g4ReR53lpFfoyI+nW8TF3SW4soL9Q5V+lrk/S/IoK8hl/x3hPR9zX8fD7f+pxz/QYLOSPW63Xj7fMZ1/DoEnsw7gabTCZUFEXrGGauvLi5wzg/8Gy329Z+59wjEroT2tYQ+flewjn34+B8gHFujSfQaWsM/dToNKlXENwZ8SogQoEIBSIUiFAgQoEIBSIUiFAgQoEIBSIUiFAgQoEIBSIUiFAgQoEIBSIUiFAgQoEI5Qv+42XD1nh67gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Path where custom images to test can be added\n",
    "# Images have to be 28 pixels x 28 pixels\n",
    "filepath = 'my_images'\n",
    "files = glob.glob(os.path.join(filepath, '*'))\n",
    "predicted_labels = \"Predicted label: \"\n",
    "n_examples = len(files)\n",
    "all_images = np.array([])\n",
    "for i in range(n_examples):\n",
    "    img = mpimg.imread(files[i])\n",
    "    img = (np.sum(img, axis=2)/3.)/255. # Flattening the image to remove RGB information. Also normalize it.\n",
    "    #img = img/255.\n",
    "    img = 1-img # So that black pixels are 'hot', and the background is white.\n",
    "    plt.subplot(1, n_examples, i+1)\n",
    "    plt.imshow(img, cmap = 'binary')\n",
    "    plt.axis('off')\n",
    "    np.append(all_images, img, axis = 0)\n",
    "    print(img.shape)\n",
    "    #predicted_labels += str(model.predict(img)) + \" \"\n",
    "    #predicted_labels += str(np.argmax(net.feedforward(img.reshape(784, 1)))) + \" \"\n",
    "    #print(model.predict(img))\n",
    "    \n",
    "print(\"Predicted_labels\")#, #model.predict(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(all_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
